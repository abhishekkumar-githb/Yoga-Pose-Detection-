{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-29T08:29:49.809794Z",
     "iopub.status.busy": "2023-11-29T08:29:49.808341Z",
     "iopub.status.idle": "2023-11-29T08:30:27.932162Z",
     "shell.execute_reply": "2023-11-29T08:30:27.930390Z",
     "shell.execute_reply.started": "2023-11-29T08:29:49.809748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.8)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (22.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (1.24.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (9.5.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:49.285348Z",
     "iopub.status.busy": "2023-11-29T08:30:49.284610Z",
     "iopub.status.idle": "2023-11-29T08:30:49.292892Z",
     "shell.execute_reply": "2023-11-29T08:30:49.291986Z",
     "shell.execute_reply.started": "2023-11-29T08:30:49.285312Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['bhujangasana', 'padmasana', 'savasana', 'tadasana', 'trikonasana', 'vrikshasana']\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data():\n",
    "    base_path = '/kaggle/input/yoga-lstm/kaggle/working/MP_Data'\n",
    "    \n",
    "    all_label_data = []\n",
    "\n",
    "    for label in labels:\n",
    "        asana_path = os.path.join(base_path, label)\n",
    "        label_data = []\n",
    "\n",
    "        for file in os.listdir(asana_path):\n",
    "            file_path = os.path.join(asana_path, file)\n",
    "            df = pd.read_csv(file_path)  # Assuming CSV contains the sequence data\n",
    "            label_data.append(df)\n",
    "\n",
    "        all_label_data.append(label_data)\n",
    "\n",
    "    return all_label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:50.442312Z",
     "iopub.status.busy": "2023-11-29T08:30:50.441598Z",
     "iopub.status.idle": "2023-11-29T08:30:50.450216Z",
     "shell.execute_reply": "2023-11-29T08:30:50.449020Z",
     "shell.execute_reply.started": "2023-11-29T08:30:50.442272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to preprocess sequences\n",
    "def preprocess_sequences(sequences):\n",
    "    sequence_length = 50\n",
    "    num_features = 6\n",
    "    processed_sequences = []\n",
    "\n",
    "    for label_data in sequences:\n",
    "        padded_sequences = []\n",
    "        for seq in label_data:\n",
    "            seq_data = seq.to_numpy()\n",
    "            if len(seq_data) >= sequence_length:\n",
    "                padded_seq = seq_data[:sequence_length, :]\n",
    "            else:\n",
    "                padded_seq = np.zeros((sequence_length, num_features))\n",
    "                padded_seq[:len(seq_data), :] = seq_data\n",
    "\n",
    "            padded_sequences.append(padded_seq)\n",
    "        processed_sequences.append(padded_sequences)\n",
    "\n",
    "    return processed_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:51.731552Z",
     "iopub.status.busy": "2023-11-29T08:30:51.731100Z",
     "iopub.status.idle": "2023-11-29T08:30:51.738842Z",
     "shell.execute_reply": "2023-11-29T08:30:51.737559Z",
     "shell.execute_reply.started": "2023-11-29T08:30:51.731515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to prepare data for training\n",
    "def prepare_data(all_label_data):\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    for i, label_data in enumerate(all_label_data):\n",
    "        for seq in label_data:\n",
    "            X_data.append(seq[:, :-1])\n",
    "            y_data.append(i)\n",
    "\n",
    "    return np.array(X_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:52.970462Z",
     "iopub.status.busy": "2023-11-29T08:30:52.969672Z",
     "iopub.status.idle": "2023-11-29T08:30:54.707146Z",
     "shell.execute_reply": "2023-11-29T08:30:54.706280Z",
     "shell.execute_reply.started": "2023-11-29T08:30:52.970421Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/kaggle/input/yoga-lstm/kaggle/working/MP_Data\\\\bhujangasana'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m all_label_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m processed_sequences \u001b[38;5;241m=\u001b[39m preprocess_sequences(all_label_data)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Prepare data for training\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m asana_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, label)\n\u001b[0;32m     11\u001b[0m label_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43masana_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(asana_path, file)\n\u001b[0;32m     15\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)  \u001b[38;5;66;03m# Assuming CSV contains the sequence data\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/kaggle/input/yoga-lstm/kaggle/working/MP_Data\\\\bhujangasana'"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "all_label_data = load_data()\n",
    "processed_sequences = preprocess_sequences(all_label_data)\n",
    "\n",
    "# Prepare data for training\n",
    "X, y = prepare_data(processed_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:54.709752Z",
     "iopub.status.busy": "2023-11-29T08:30:54.709069Z",
     "iopub.status.idle": "2023-11-29T08:30:54.723958Z",
     "shell.execute_reply": "2023-11-29T08:30:54.723032Z",
     "shell.execute_reply.started": "2023-11-29T08:30:54.709717Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Convert the input data to the appropriate data type\u001b[39;00m\n\u001b[0;32m      6\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Convert the input data to the appropriate data type\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "# Ensure y_train and y_test are one-hot encoded for multi-class classification\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:55.368154Z",
     "iopub.status.busy": "2023-11-29T08:30:55.367276Z",
     "iopub.status.idle": "2023-11-29T08:30:55.376199Z",
     "shell.execute_reply": "2023-11-29T08:30:55.374749Z",
     "shell.execute_reply.started": "2023-11-29T08:30:55.368114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:56.467311Z",
     "iopub.status.busy": "2023-11-29T08:30:56.466886Z",
     "iopub.status.idle": "2023-11-29T08:30:56.652847Z",
     "shell.execute_reply": "2023-11-29T08:30:56.651509Z",
     "shell.execute_reply.started": "2023-11-29T08:30:56.467275Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:30:57.735354Z",
     "iopub.status.busy": "2023-11-29T08:30:57.734922Z",
     "iopub.status.idle": "2023-11-29T08:30:59.090882Z",
     "shell.execute_reply": "2023-11-29T08:30:59.089632Z",
     "shell.execute_reply.started": "2023-11-29T08:30:57.735317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50, 128)           69120     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 50, 128)           512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50, 128)           131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50, 128)           0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 50, 128)           512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 334598 (1.28 MB)\n",
      "Trainable params: 333830 (1.27 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add LSTM layers with dropout and batch normalization\n",
    "model.add(LSTM(units=128, return_sequences=True, input_shape=(50, 6)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add a Dense output layer for classification\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:39:14.871021Z",
     "iopub.status.busy": "2023-11-29T08:39:14.870598Z",
     "iopub.status.idle": "2023-11-29T08:40:23.431606Z",
     "shell.execute_reply": "2023-11-29T08:40:23.430380Z",
     "shell.execute_reply.started": "2023-11-29T08:39:14.870991Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train_encoded, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[tb_callback])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train_encoded, epochs=100, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:40:23.435313Z",
     "iopub.status.busy": "2023-11-29T08:40:23.434898Z",
     "iopub.status.idle": "2023-11-29T08:40:23.570304Z",
     "shell.execute_reply": "2023-11-29T08:40:23.569482Z",
     "shell.execute_reply.started": "2023-11-29T08:40:23.435277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, 4, 2, 0, 5, 2, 2, 0, 2, 4, 3, 5, 4, 2, 1, 2, 5, 3, 0, 4,\n",
       "       4, 4, 2, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "predicted_labels = np.argmax(y_pred, axis=1)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:40:23.571964Z",
     "iopub.status.busy": "2023-11-29T08:40:23.571623Z",
     "iopub.status.idle": "2023-11-29T08:40:23.579597Z",
     "shell.execute_reply": "2023-11-29T08:40:23.578479Z",
     "shell.execute_reply.started": "2023-11-29T08:40:23.571934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, 4, 2, 0, 5, 2, 2, 0, 2, 3, 3, 5, 4, 2, 1, 2, 5, 3, 0, 4,\n",
       "       4, 4, 2, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T08:46:29.753831Z",
     "iopub.status.busy": "2023-11-29T08:46:29.753434Z",
     "iopub.status.idle": "2023-11-29T08:46:29.760751Z",
     "shell.execute_reply": "2023-11-29T08:46:29.759511Z",
     "shell.execute_reply.started": "2023-11-29T08:46:29.753801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i]==predicted_labels[i]:\n",
    "        x+=1\n",
    "print(x/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rathi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm10fps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('lstm10fps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    x1, y1, z1 = landmark1\n",
    "    x2, y2, z2 = landmark2\n",
    "    x3, y3, z3 = landmark3\n",
    "    \n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classifyAngles_check(landmarks):\n",
    "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    \n",
    "    # Get the angle between the right shoulder, elbow and wrist points. \n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])   \n",
    "    \n",
    "    # Get the angle between the left elbow, shoulder and hip points. \n",
    "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "\n",
    "    # Get the angle between the right hip, shoulder and elbow points. \n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "    # Get the angle between the left hip, knee and ankle points. \n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    # Get the angle between the right hip, knee and ankle points \n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "\n",
    "#     print(f\"Left Elbow Angle: {left_elbow_angle}, \"\n",
    "#           f\"Right Elbow Angle: {right_elbow_angle}, \"\n",
    "#           f\"Left Shoulder Angle: {left_shoulder_angle}, \"\n",
    "#           f\"Right Shoulder Angle: {right_shoulder_angle}, \"\n",
    "#           f\"Left Knee Angle: {left_knee_angle}, \"\n",
    "#           f\"Right Knee Angle: {right_knee_angle}\")\n",
    "    \n",
    "    return [left_elbow_angle,right_elbow_angle,left_shoulder_angle,right_shoulder_angle,left_knee_angle,right_knee_angle]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "labels = ['bhujangasana', 'padmasana', 'savasana', 'tadasana', 'trikonasana', 'vrikshasana']\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "frame_count = 0\n",
    "frames_data = []\n",
    "capture_frames = False\n",
    "prediction = \"\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # If 'c' is pressed, start capturing frames\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('c'):\n",
    "        capture_frames = not capture_frames  # Toggle capturing frames\n",
    "\n",
    "        # Reset frame count and frames_data when starting to capture frames\n",
    "        if capture_frames:\n",
    "            frame_count = 0\n",
    "            frames_data = []\n",
    "    \n",
    "    if capture_frames:\n",
    "        # Process the frame to detect poses\n",
    "        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            # Draw the detected poses on the frame\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            height, width, _ = frame.shape\n",
    "            rows = 33\n",
    "            cols = 3\n",
    "            landmarks = [[0 for _ in range(cols)] for _ in range(rows)]\n",
    "            landmark = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get pose landmarks and store them for prediction\n",
    "            for i in range(len(landmark)):\n",
    "                landmarks[i] = ((landmark[i].x * width, landmark[i].y * height, landmark[i].z * width))\n",
    "            angles = classifyAngles_check(landmarks)\n",
    "\n",
    "            frames_data.append(angles)\n",
    "            frame_count += 1\n",
    "\n",
    "            # If 125 frames captured, perform prediction\n",
    "            if frame_count == 125:\n",
    "                # Convert frames_data to numpy array for prediction (shape: (125, 33, 3))\n",
    "                frames_array = np.array(frames_data)\n",
    "                frames_array = frames_array.reshape((1, 125, 6))\n",
    "\n",
    "                # Perform prediction\n",
    "                output = loaded_model.predict(frames_array)\n",
    "                predicted_label = np.argmax(output)\n",
    "                prediction = labels[predicted_label]\n",
    "\n",
    "                frame_count = 0\n",
    "                frames_data = []\n",
    "\n",
    "    # Display prediction on the OpenCV window\n",
    "    cv2.putText(frame, f\"Prediction: {prediction}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4024990,
     "sourceId": 7001610,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4030779,
     "sourceId": 7010772,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4037035,
     "sourceId": 7020516,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4048567,
     "sourceId": 7037117,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
