{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7001610,"sourceType":"datasetVersion","datasetId":4024990},{"sourceId":7010772,"sourceType":"datasetVersion","datasetId":4030779},{"sourceId":7013119,"sourceType":"datasetVersion","datasetId":4032272},{"sourceId":7013195,"sourceType":"datasetVersion","datasetId":4032327}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mediapipe\nimport os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport mediapipe as mp\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-20T18:41:54.147782Z","iopub.execute_input":"2023-11-20T18:41:54.148781Z","iopub.status.idle":"2023-11-20T18:42:15.966523Z","shell.execute_reply.started":"2023-11-20T18:41:54.148743Z","shell.execute_reply":"2023-11-20T18:42:15.965664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing and Database construction","metadata":{}},{"cell_type":"code","source":"# Initialize mediapipe pose model\nmp_pose = mp.solutions.pose\nmp_drawing = mp.solutions.drawing_utils\npose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n\n# Path to the directory containing videos\nvideos_path = '/kaggle/input/yoga-part-2/yoga_videos'\nasanas = ['bhujangasana', 'padmasana', 'savasana', 'tadasana', 'trikonasana', 'vrikshasana']\n# Initialize DataFrame and columns\ncolumns = ['Left Elbow Angle', 'Right Elbow Angle', 'Left Shoulder Angle', 'Right Shoulder Angle', 'Left Knee Angle', 'Right Knee Angle', 'Label']\ndf = pd.DataFrame(columns=columns)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:42:15.968659Z","iopub.execute_input":"2023-11-20T18:42:15.969652Z","iopub.status.idle":"2023-11-20T18:42:16.006794Z","shell.execute_reply.started":"2023-11-20T18:42:15.969614Z","shell.execute_reply":"2023-11-20T18:42:16.003326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detectPose(image, pose, display=False):\n    output_image = image.copy()\n    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    results = pose.process(imageRGB)\n    height, width, _ = image.shape\n    rows = 33\n    cols = 3\n    landmarks = [[0 for _ in range(cols)] for _ in range(rows)]\n#     landmarks = []\n    drawing_spec = mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=6, circle_radius=16)\n    if results.pose_landmarks:\n        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n                                  connections=mp_pose.POSE_CONNECTIONS,landmark_drawing_spec=drawing_spec,connection_drawing_spec=drawing_spec)\n        landmark = results.pose_landmarks.landmark\n        for i in range(len(landmark)):\n#         for landmark in results.pose_landmarks.landmark:\n            landmarks[i] = ((landmark[i].x * width, landmark[i].y * height, landmark[i].z * width))\n\n    if display:\n        plt.figure(figsize=[22,22])\n        plt.subplot(121); plt.imshow(image[:,:,::-1]); plt.title(\"Original Image\"); plt.axis('off');\n        plt.subplot(122); plt.imshow(output_image[:,:,::-1]); plt.title(\"Output Image\"); plt.axis('off');\n        plt.show()\n    else:\n        return output_image, landmarks","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:42:16.008774Z","iopub.execute_input":"2023-11-20T18:42:16.009182Z","iopub.status.idle":"2023-11-20T18:42:16.026698Z","shell.execute_reply.started":"2023-11-20T18:42:16.009144Z","shell.execute_reply":"2023-11-20T18:42:16.025428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_path = '/kaggle/input/bhujangasana-pose/sumit.png'\ntest_image = cv2.imread(test_image_path)\ndetectPose(test_image,pose,display=True)\ntest_ouput, test_landmark = detectPose(test_image,pose,display=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:10:31.932114Z","iopub.execute_input":"2023-11-20T20:10:31.933163Z","iopub.status.idle":"2023-11-20T20:10:33.130279Z","shell.execute_reply.started":"2023-11-20T20:10:31.933112Z","shell.execute_reply":"2023-11-20T20:10:33.129445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:42:16.028798Z","iopub.execute_input":"2023-11-20T18:42:16.029099Z","iopub.status.idle":"2023-11-20T18:42:16.048332Z","shell.execute_reply.started":"2023-11-20T18:42:16.029064Z","shell.execute_reply":"2023-11-20T18:42:16.047379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '/kaggle/input/yoga-pose-image/young-man-is-making-yoga-isolated-white-background.jpg'\nimage = cv2.imread(image_path)\ndetectPose(image,pose,display=True)\nsample_output,sample_landmark=detectPose(image,pose,display=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:27:48.730494Z","iopub.execute_input":"2023-11-20T17:27:48.730862Z","iopub.status.idle":"2023-11-20T17:27:54.292784Z","shell.execute_reply.started":"2023-11-20T17:27:48.730832Z","shell.execute_reply":"2023-11-20T17:27:54.291978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(sample_landmark))\nprint(len(sample_landmark[0]))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:13:24.984007Z","iopub.execute_input":"2023-11-20T16:13:24.984292Z","iopub.status.idle":"2023-11-20T16:13:24.989342Z","shell.execute_reply.started":"2023-11-20T16:13:24.984266Z","shell.execute_reply":"2023-11-20T16:13:24.988478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculateAngle(landmark1, landmark2, landmark3):\n    x1, y1, z1 = landmark1\n    x2, y2, z2 = landmark2\n    x3, y3, z3 = landmark3\n    \n    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n    if angle < 0:\n        angle += 360\n    \n    return angle","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:58:46.877949Z","iopub.execute_input":"2023-11-20T19:58:46.878916Z","iopub.status.idle":"2023-11-20T19:58:46.884573Z","shell.execute_reply.started":"2023-11-20T19:58:46.878877Z","shell.execute_reply":"2023-11-20T19:58:46.883607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classifyAngles(df, landmarks, label):\n    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n    \n    # Get the angle between the right shoulder, elbow and wrist points. \n    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])   \n    \n    # Get the angle between the left elbow, shoulder and hip points. \n    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n\n    # Get the angle between the right hip, shoulder and elbow points. \n    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n\n    # Get the angle between the left hip, knee and ankle points. \n    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n\n    # Get the angle between the right hip, knee and ankle points \n    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n\n#     df = df.append({'Left Elbow Angle': left_elbow_angle,\n#                     'Right Elbow Angle': right_elbow_angle,\n#                     'Left Shoulder Angle': left_shoulder_angle,\n#                     'Right Shoulder Angle': right_shoulder_angle,\n#                     'Left Knee Angle': left_knee_angle,\n#                     'Right Knee Angle': right_knee_angle,\n#                     'Label': label}, ignore_index=True)\n    \n    df.loc[len(df.index)] = [left_elbow_angle,right_elbow_angle,left_shoulder_angle,right_shoulder_angle,left_knee_angle,right_knee_angle,label] \n\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:42:30.238743Z","iopub.execute_input":"2023-11-20T18:42:30.239648Z","iopub.status.idle":"2023-11-20T18:42:30.249445Z","shell.execute_reply.started":"2023-11-20T18:42:30.239610Z","shell.execute_reply":"2023-11-20T18:42:30.248373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef classifyAngles_check(landmarks):\n    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n    \n    # Get the angle between the right shoulder, elbow and wrist points. \n    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n                                       landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n                                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])   \n    \n    # Get the angle between the left elbow, shoulder and hip points. \n    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n\n    # Get the angle between the right hip, shoulder and elbow points. \n    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n                                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n\n    # Get the angle between the left hip, knee and ankle points. \n    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n\n    # Get the angle between the right hip, knee and ankle points \n    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n                                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n                                      landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n\n    print(f\"Left Elbow Angle: {left_elbow_angle}, \"\n          f\"Right Elbow Angle: {right_elbow_angle}, \"\n          f\"Left Shoulder Angle: {left_shoulder_angle}, \"\n          f\"Right Shoulder Angle: {right_shoulder_angle}, \"\n          f\"Left Knee Angle: {left_knee_angle}, \"\n          f\"Right Knee Angle: {right_knee_angle}\")\n    \n    return [left_elbow_angle,right_elbow_angle,left_shoulder_angle,right_shoulder_angle,left_knee_angle,right_knee_angle]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:58:52.581382Z","iopub.execute_input":"2023-11-20T19:58:52.581785Z","iopub.status.idle":"2023-11-20T19:58:52.591663Z","shell.execute_reply.started":"2023-11-20T19:58:52.581751Z","shell.execute_reply":"2023-11-20T19:58:52.590586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = classifyAngles_check(sample_landmark)\n# sample_df = pd.DataFrame(columns=columns)\nsample_dict = {'Left Elbow Angle':[],'Right Elbow Angle':[], 'Left Shoulder Angle':[], 'Right Shoulder Angle':[], 'Left Knee Angle':[], 'Right Knee Angle':[]}\nsample_df = pd.DataFrame(sample_dict)\nsample_df.loc[len(sample_df.index)] = list(sample)\nprint(sample_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:28:18.045112Z","iopub.execute_input":"2023-11-20T17:28:18.046026Z","iopub.status.idle":"2023-11-20T17:28:18.055556Z","shell.execute_reply.started":"2023-11-20T17:28:18.045990Z","shell.execute_reply":"2023-11-20T17:28:18.054629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = classifyAngles_check(test_landmark)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:10:47.756002Z","iopub.execute_input":"2023-11-20T20:10:47.756399Z","iopub.status.idle":"2023-11-20T20:10:47.761615Z","shell.execute_reply.started":"2023-11-20T20:10:47.756370Z","shell.execute_reply":"2023-11-20T20:10:47.760572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['Left Elbow Angle', 'Right Elbow Angle', 'Left Shoulder Angle', 'Right Shoulder Angle', 'Left Knee Angle', 'Right Knee Angle', 'Label']\ndictionary = {'Left Elbow Angle':[],'Right Elbow Angle':[], 'Left Shoulder Angle':[], 'Right Shoulder Angle':[], 'Left Knee Angle':[], 'Right Knee Angle':[], 'Label':[]}\ndf = pd.DataFrame(dictionary)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:28:31.073976Z","iopub.execute_input":"2023-11-20T17:28:31.074882Z","iopub.status.idle":"2023-11-20T17:28:31.085407Z","shell.execute_reply.started":"2023-11-20T17:28:31.074848Z","shell.execute_reply":"2023-11-20T17:28:31.084401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate through each video\nfor label in os.listdir(videos_path):\n    video_path = os.path.join(videos_path, label)\n    \n    # Capture video\n    cap = cv2.VideoCapture(video_path)\n    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    clip_duration = 120  # Duration to capture frames in seconds\n    \n    # Capture frames for the specified duration\n    frames_to_capture = int(clip_duration * frame_rate)\n    frames_collected = 0\n    \n    while frames_collected < frames_to_capture:\n        ret, frame = cap.read()\n        \n        if not ret:\n            break\n        \n        # Process frame to detect pose\n        _, landmarks = detectPose(frame, pose, display=False)\n        \n        # Classify angles and add to DataFrame\n        df = classifyAngles(df, landmarks, label)\n        \n        frames_collected += 1\n        \n    cap.release()\n\n# Display or save DataFrame\nprint(df.head())\n\ndf.to_csv('yoga_poses_dataset.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:28:41.213388Z","iopub.execute_input":"2023-11-20T17:28:41.213773Z","iopub.status.idle":"2023-11-20T17:38:37.791278Z","shell.execute_reply.started":"2023-11-20T17:28:41.213740Z","shell.execute_reply":"2023-11-20T17:38:37.790392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split and Training","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:42:45.962522Z","iopub.execute_input":"2023-11-20T18:42:45.962929Z","iopub.status.idle":"2023-11-20T18:42:46.699224Z","shell.execute_reply.started":"2023-11-20T18:42:45.962897Z","shell.execute_reply":"2023-11-20T18:42:46.698381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asanas = ['bhujangasana', 'padmasana', 'savasana', 'tadasana', 'trikonasana', 'vrikshasana']\nlabels = list()\nfor x in asanas:\n    labels.append(x+'.mp4')\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:42:53.238670Z","iopub.execute_input":"2023-11-20T18:42:53.239067Z","iopub.status.idle":"2023-11-20T18:42:53.246551Z","shell.execute_reply.started":"2023-11-20T18:42:53.239034Z","shell.execute_reply":"2023-11-20T18:42:53.245619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/yoga_poses_dataset.csv')\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:43:59.028554Z","iopub.execute_input":"2023-11-20T18:43:59.029588Z","iopub.status.idle":"2023-11-20T18:43:59.083138Z","shell.execute_reply.started":"2023-11-20T18:43:59.029547Z","shell.execute_reply":"2023-11-20T18:43:59.082140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_map = {label:num for num,label in enumerate(labels)}\nlabel_map","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:44:50.931713Z","iopub.execute_input":"2023-11-20T18:44:50.932415Z","iopub.status.idle":"2023-11-20T18:44:50.939191Z","shell.execute_reply.started":"2023-11-20T18:44:50.932379Z","shell.execute_reply":"2023-11-20T18:44:50.938251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Separate features (X) and target (y)\nX = df.drop('Label', axis=1)  # Features\ny = df['Label']  # Target","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:49:46.448094Z","iopub.execute_input":"2023-11-20T18:49:46.448918Z","iopub.status.idle":"2023-11-20T18:49:46.466382Z","shell.execute_reply.started":"2023-11-20T18:49:46.448878Z","shell.execute_reply":"2023-11-20T18:49:46.465553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# Encode categorical labels using LabelEncoder\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:03:42.842776Z","iopub.execute_input":"2023-11-20T19:03:42.843233Z","iopub.status.idle":"2023-11-20T19:03:42.854820Z","shell.execute_reply.started":"2023-11-20T19:03:42.843198Z","shell.execute_reply":"2023-11-20T19:03:42.853849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:04:07.675283Z","iopub.execute_input":"2023-11-20T19:04:07.676052Z","iopub.status.idle":"2023-11-20T19:04:07.684889Z","shell.execute_reply.started":"2023-11-20T19:04:07.676017Z","shell.execute_reply":"2023-11-20T19:04:07.683900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:51:17.084293Z","iopub.execute_input":"2023-11-20T18:51:17.085105Z","iopub.status.idle":"2023-11-20T18:51:17.091948Z","shell.execute_reply.started":"2023-11-20T18:51:17.085061Z","shell.execute_reply":"2023-11-20T18:51:17.090878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(6, activation='softmax')  # Adjust output neurons based on your classification categories\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:51:34.524731Z","iopub.execute_input":"2023-11-20T18:51:34.525016Z","iopub.status.idle":"2023-11-20T18:51:37.569088Z","shell.execute_reply.started":"2023-11-20T18:51:34.524991Z","shell.execute_reply":"2023-11-20T18:51:37.568172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import TensorBoard\nlog_dir = os.path.join('Logs')\ntb_callback = TensorBoard(log_dir=log_dir)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:53:17.821437Z","iopub.execute_input":"2023-11-20T18:53:17.822458Z","iopub.status.idle":"2023-11-20T18:53:17.832886Z","shell.execute_reply.started":"2023-11-20T18:53:17.822417Z","shell.execute_reply":"2023-11-20T18:53:17.832084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=250, batch_size=64, validation_split=0.1, callbacks=[TensorBoard()])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:04:55.390244Z","iopub.execute_input":"2023-11-20T19:04:55.391080Z","iopub.status.idle":"2023-11-20T19:09:04.557202Z","shell.execute_reply.started":"2023-11-20T19:04:55.391046Z","shell.execute_reply":"2023-11-20T19:09:04.556168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:09:44.892634Z","iopub.execute_input":"2023-11-20T19:09:44.893035Z","iopub.status.idle":"2023-11-20T19:09:45.471324Z","shell.execute_reply.started":"2023-11-20T19:09:44.893002Z","shell.execute_reply":"2023-11-20T19:09:45.470445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numpy_test = np.array(test)\nnumpy_test = np.expand_dims(numpy_test, axis=0)\nnumpy_test\n# test_res = model.predict(numpy_test)\n# test_res","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:11:05.820713Z","iopub.execute_input":"2023-11-20T20:11:05.821504Z","iopub.status.idle":"2023-11-20T20:11:05.828372Z","shell.execute_reply.started":"2023-11-20T20:11:05.821457Z","shell.execute_reply":"2023-11-20T20:11:05.827307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = loaded_model.predict(numpy_test)\n\n# Print or use the output as needed\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:11:13.548898Z","iopub.execute_input":"2023-11-20T20:11:13.549645Z","iopub.status.idle":"2023-11-20T20:11:13.615889Z","shell.execute_reply.started":"2023-11-20T20:11:13.549608Z","shell.execute_reply":"2023-11-20T20:11:13.614895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_probabilities = np.array([[7.6863284e-07, 8.7133900e-09, 1.9854947e-06, 9.9997902e-01, 1.8023882e-05, 7.0292941e-08]])\n\n# Get the predicted label (index of the highest probability)\npredicted_label = np.argmax(output)\npredicted_label","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:11:58.554183Z","iopub.execute_input":"2023-11-20T20:11:58.555266Z","iopub.status.idle":"2023-11-20T20:11:58.562096Z","shell.execute_reply.started":"2023-11-20T20:11:58.555229Z","shell.execute_reply":"2023-11-20T20:11:58.561169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for lab,num in label_map.items():\n    if num==predicted_label:\n        print(lab)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:48:47.026467Z","iopub.execute_input":"2023-11-20T20:48:47.026880Z","iopub.status.idle":"2023-11-20T20:48:47.032550Z","shell.execute_reply.started":"2023-11-20T20:48:47.026850Z","shell.execute_reply":"2023-11-20T20:48:47.031565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'predicted asana: {asanas[np.argmax(res[60])]}')\nprint(f'actual asana: {asanas[np.argmax(y_test[60])]}')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:11:06.934794Z","iopub.execute_input":"2023-11-20T19:11:06.935525Z","iopub.status.idle":"2023-11-20T19:11:06.941257Z","shell.execute_reply.started":"2023-11-20T19:11:06.935492Z","shell.execute_reply":"2023-11-20T19:11:06.940496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Data types in X_train:\")\nprint(X_train.dtypes)\n\nprint(\"\\nData types in y_train:\")\nprint(y_train.dtypes)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T18:58:30.979037Z","iopub.execute_input":"2023-11-20T18:58:30.979830Z","iopub.status.idle":"2023-11-20T18:58:30.986847Z","shell.execute_reply.started":"2023-11-20T18:58:30.979792Z","shell.execute_reply":"2023-11-20T18:58:30.985823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation using Confusion Matrix and Accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import multilabel_confusion_matrix\n\n# Assuming y_test is not one-hot encoded\nyhat = model.predict(X_test)\nyhat_labels = np.argmax(yhat, axis=1)  # Convert probabilities to integer labels\n\nconfusion_matrix = multilabel_confusion_matrix(y_true=y_test, y_pred=yhat_labels)\nprint(\"Multilabel Confusion Matrix:\")\nprint(confusion_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:34:02.954481Z","iopub.execute_input":"2023-11-20T19:34:02.955709Z","iopub.status.idle":"2023-11-20T19:34:03.368676Z","shell.execute_reply.started":"2023-11-20T19:34:02.955665Z","shell.execute_reply":"2023-11-20T19:34:03.367625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Assuming y_test is not one-hot encoded\nyhat = model.predict(X_test)\nyhat_labels = np.argmax(yhat, axis=1)  # Convert probabilities to integer labels\n\naccuracy = accuracy_score(y_true=y_test, y_pred=yhat_labels)\nprint(\"Accuracy Score:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:35:53.953850Z","iopub.execute_input":"2023-11-20T19:35:53.954743Z","iopub.status.idle":"2023-11-20T19:35:54.359398Z","shell.execute_reply.started":"2023-11-20T19:35:53.954706Z","shell.execute_reply":"2023-11-20T19:35:54.358355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:30:05.238146Z","iopub.execute_input":"2023-11-20T19:30:05.239049Z","iopub.status.idle":"2023-11-20T19:30:05.245261Z","shell.execute_reply.started":"2023-11-20T19:30:05.239008Z","shell.execute_reply":"2023-11-20T19:30:05.244318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Assuming y_test is not one-hot encoded\nyhat = model.predict(X_test)\nyhat_labels = np.argmax(yhat, axis=1)  # Convert probabilities to integer labels\n\nreport = classification_report(y_true=y_test, y_pred=yhat_labels)\nprint(\"Classification Report:\\n\", report)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:38:03.796607Z","iopub.execute_input":"2023-11-20T19:38:03.797614Z","iopub.status.idle":"2023-11-20T19:38:04.222459Z","shell.execute_reply.started":"2023-11-20T19:38:03.797573Z","shell.execute_reply":"2023-11-20T19:38:04.221421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Weights","metadata":{}},{"cell_type":"code","source":"model.save('action.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:41:07.115115Z","iopub.execute_input":"2023-11-20T19:41:07.115994Z","iopub.status.idle":"2023-11-20T19:41:07.175957Z","shell.execute_reply.started":"2023-11-20T19:41:07.115956Z","shell.execute_reply":"2023-11-20T19:41:07.174849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the saved model\nloaded_model = load_model('action.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T19:43:49.047585Z","iopub.execute_input":"2023-11-20T19:43:49.048073Z","iopub.status.idle":"2023-11-20T19:43:49.242230Z","shell.execute_reply.started":"2023-11-20T19:43:49.048025Z","shell.execute_reply":"2023-11-20T19:43:49.241179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up pipeline","metadata":{}},{"cell_type":"code","source":"def prediction_pipeline(test_image):\n    # get the landmark\n    realtime_output, realtime_landmark = detectPose(test_image, pose, display=False)\n    \n    # get the angles\n    realtime_angles = classifyAngles_check(realtime_landmark)\n    \n    # create a numpy array for angles\n    numpy_realtime = np.array(realtime_angles)\n    numpy_realtime = np.expand_dims(numpy_realtime, axis=0)\n    \n    # predict the output\n    output = loaded_model.predict(numpy_realtime)\n    \n    # get predicted label\n    predicted_label = np.argmax(output)\n    \n    # find corresponding label name\n    realtime_label = str()\n    for lab, num in label_map.items():\n        if num == predicted_label:\n            # Return the whole string except the last 4 characters\n            realtime_label = lab[:-4]\n\n    return realtime_label","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:53:07.470034Z","iopub.execute_input":"2023-11-20T20:53:07.470854Z","iopub.status.idle":"2023-11-20T20:53:07.477827Z","shell.execute_reply.started":"2023-11-20T20:53:07.470815Z","shell.execute_reply":"2023-11-20T20:53:07.476698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_path = '/kaggle/input/bhujangasana-pose/sumit.png'\ntest_image = cv2.imread(test_image_path)\ntest_label_output = prediction_pipeline(test_image)\nprint(test_label_output)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T20:55:20.203360Z","iopub.execute_input":"2023-11-20T20:55:20.204114Z","iopub.status.idle":"2023-11-20T20:55:20.353333Z","shell.execute_reply.started":"2023-11-20T20:55:20.204076Z","shell.execute_reply":"2023-11-20T20:55:20.352401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def detection_pipeline(test_image):\n    detectPose(test_image, pose, display=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:08:05.057072Z","iopub.execute_input":"2023-11-20T21:08:05.057626Z","iopub.status.idle":"2023-11-20T21:08:05.062909Z","shell.execute_reply.started":"2023-11-20T21:08:05.057586Z","shell.execute_reply":"2023-11-20T21:08:05.061858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Realtime Detection and Prediction using Webcam Feed","metadata":{}},{"cell_type":"code","source":"# Initialize OpenCV video capture\ncap = cv2.VideoCapture(0)\n\n# Variables to control the timer\ntimer_started = False\nstart_time = None\n\n# Main loop to capture frames from the webcam\nwhile True:\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    # Check for key press events\n    key = cv2.waitKey(1) & 0xFF\n\n    # Start the timer on 'c' key press\n    if key == ord('c'):\n        timer_started = True\n        start_time = time.time()\n        seconds = 0\n\n    if timer_started:\n        # Calculate elapsed time\n        seconds = int(time.time() - start_time)\n\n        # Display the timer on the frame\n        cv2.putText(frame, f'Timer: {seconds}', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n\n        if seconds == 5:\n            # Run classification function after 5 seconds\n            result = prediction_pipeline(frame)\n            \n            # Display the classification result on the frame\n            cv2.putText(frame, f'Predicted: {result}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2)\n            \n        # Run detection function every second\n        if seconds % 1 == 0:\n            detection_pipeline(frame)\n\n    # Show the frame\n    cv2.imshow('Frame', frame)\n    \n    # Exit loop on 'q' key press\n    if key == ord('q'):\n        break\n\n# Release the video capture and close all windows\ncap.release()\n# cv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:45:50.052049Z","iopub.execute_input":"2023-11-20T21:45:50.053082Z","iopub.status.idle":"2023-11-20T21:45:50.063140Z","shell.execute_reply.started":"2023-11-20T21:45:50.053043Z","shell.execute_reply":"2023-11-20T21:45:50.062078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r working.zip /kaggle/working\n!ls\nfrom IPython.display import FileLink\nFileLink(r'working.zip')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:55:30.809796Z","iopub.execute_input":"2023-11-20T21:55:30.810568Z","iopub.status.idle":"2023-11-20T21:55:33.030315Z","shell.execute_reply.started":"2023-11-20T21:55:30.810531Z","shell.execute_reply":"2023-11-20T21:55:33.029308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r yoga_videos.zip /kaggle/input/yoga-part-2/yoga_videos\n!ls\nfrom IPython.display import FileLink\nFileLink(r'yoga_videos.zip')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:57:01.431156Z","iopub.execute_input":"2023-11-20T21:57:01.432258Z","iopub.status.idle":"2023-11-20T21:57:08.799986Z","shell.execute_reply.started":"2023-11-20T21:57:01.432213Z","shell.execute_reply":"2023-11-20T21:57:08.798950Z"},"trusted":true},"execution_count":null,"outputs":[]}]}